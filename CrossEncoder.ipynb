{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"../../data/documents.jsonl\") as f:\n",
    "    docs = [json.loads(line) for line in f]\n",
    "\n",
    "# questions_from_contents.jsonl 파일은 Generate_questions_from_content.ipynb 를 실행하면 생성됨.\n",
    "with open(\"questions_from_contents.jsonl\") as f:\n",
    "    qfcs = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qfcs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import InputExample\n",
    "import random\n",
    "\n",
    "max_c_idx = len(docs) - 1\n",
    "train_samples = []\n",
    "eval_samples = []\n",
    "\n",
    "for i, qfc in enumerate(qfcs):\n",
    "    is_for_train = True\n",
    "    \n",
    "    # 일부만 평가용으로 사용하자\n",
    "    if i % 10 >= 7:\n",
    "        is_for_train = False\n",
    "    \n",
    "    c_idx = qfc['docOffset']\n",
    "    \n",
    "    mc_idx = random.randint(0, max_c_idx)\n",
    "    while mc_idx == c_idx:\n",
    "        mc_idx = random.randint(0, max_c_idx)\n",
    "    \n",
    "    if is_for_train:\n",
    "        train_samples.append(\n",
    "            InputExample(texts=[qfc['question'], docs[c_idx]['content']], label=1)\n",
    "        )\n",
    "        train_samples.append(\n",
    "            InputExample(texts=[qfc['question'], docs[mc_idx]['content']], label=0)\n",
    "        )\n",
    "    else:\n",
    "        eval_samples.append(\n",
    "            InputExample(texts=[qfc['question'], docs[c_idx]['content']], label=1)\n",
    "        )\n",
    "        eval_samples.append(\n",
    "            InputExample(texts=[qfc['question'], docs[mc_idx]['content']], label=0)\n",
    "        )\n",
    "    \n",
    "    # print(f\"question: {qfc['question']}\")\n",
    "    # print(f\"      c_idx: {c_idx}, content: {docs[c_idx]['content']}\")\n",
    "    # print(f\"      mc_idx: {mc_idx}, content: {docs[mc_idx]['content']}\")\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_samples), len(eval_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "\n",
    "cross_model = CrossEncoder('klue/roberta-small', num_labels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.cross_encoder.evaluation import CECorrelationEvaluator\n",
    "\n",
    "ce_evaluator = CECorrelationEvaluator.from_input_examples(eval_samples)\n",
    "ce_evaluator(cross_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_batch_size = 16\n",
    "num_epochs = 2\n",
    "model_save_path = 'output/training_qfc'\n",
    "\n",
    "train_dataloader = DataLoader(train_samples, shuffle=True, batch_size=train_batch_size)\n",
    "\n",
    "cross_model.fit(\n",
    "    train_dataloader=train_dataloader,\n",
    "    epochs=num_epochs,\n",
    "    warmup_steps=100,\n",
    "    output_path=model_save_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_model.save(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_evaluator(cross_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "login(token=os.getenv('HF_TOKEN'))\n",
    "api = HfApi()\n",
    "repo_id = 'klue-roberta-small-cross-encoder-temp'\n",
    "api.create_repo(repo_id=repo_id)\n",
    "\n",
    "api.upload_folder(\n",
    "    folder_path=model_save_path,\n",
    "    repo_id=f\"Kerneld/{repo_id}\",\n",
    "    repo_type=\"model\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
